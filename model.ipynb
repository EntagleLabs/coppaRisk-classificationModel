{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9deaaa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import FunctionTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "338c039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "data_target = pd.read_csv(\"target.csv\")\n",
    "submission = pd.read_csv(\"submission.csv\")\n",
    "submission_format = pd.read_csv(\"submission_format2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69da0b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = pd.concat([data_train,data_target],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da40373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data.to_csv(\"train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a7e3f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy scores:  [0.89928571 0.90571429 0.90214286 0.89214286 0.89857143]\n",
      "Rata-rata CV Accuracy:  0.8995714285714286\n",
      "File submission.csv telah disimpan.\n"
     ]
    }
   ],
   "source": [
    "# Fungsi khusus untuk mengonversi kolom Downloads yang berupa rentang (ex: \"100000 - 500000\")\n",
    "def parse_download_range(X):\n",
    "    # Jika X adalah DataFrame, ambil kolom pertama sebagai array\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.iloc[:, 0].values\n",
    "    # Jika X adalah Series, kita sudah bisa mengakses nilainya dengan .values\n",
    "    # Pastikan bahwa X sekarang adalah array NumPy\n",
    "    def convert_range(s):\n",
    "        try:\n",
    "            # Pastikan s adalah string, lalu bagi berdasarkan '-'\n",
    "            parts = str(s).split('-')\n",
    "            if len(parts) != 2:\n",
    "                return np.nan\n",
    "            # Hilangkan spasi dan koma, kemudian konversi ke float\n",
    "            low = float(parts[0].strip().replace(',', ''))\n",
    "            high = float(parts[1].strip().replace(',', ''))\n",
    "            # Kembalikan rata-rata dari dua angka tersebut\n",
    "            return (low + high) / 2\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    # Terapkan fungsi ke tiap elemen dan pastikan keluaran berbentuk (n_samples, 1)\n",
    "    result = np.array([convert_range(val) for val in X])\n",
    "    return result.reshape(-1, 1)\n",
    "\n",
    "# Buat transformer khusus dari fungsi di atas\n",
    "download_transformer = FunctionTransformer(parse_download_range, validate=False)\n",
    "\n",
    "# --- MEMBACA DATA ---\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "submission_format = pd.read_csv(\"submission_format.csv\")\n",
    "# Jika file target.csv diperlukan untuk keperluan mapping, bisa juga dibaca\n",
    "# target_df = pd.read_csv(\"target.csv\")\n",
    "\n",
    "# Misal, target variabel adalah kolom 'coppaRisk' (pastikan sesuai dengan nama kolom di file Anda)\n",
    "target_column = \"coppaRisk\"\n",
    "\n",
    "# Pisahkan fitur dan target dari data latih\n",
    "X_train = train_df.drop(columns=[target_column])\n",
    "y_train = train_df[target_column]\n",
    "\n",
    "# --- MENDEFINISIKAN FITUR UNTUK PREPROCESSING ---\n",
    "\n",
    "# Fitur numerik yang secara langsung dapat digunakan\n",
    "numeric_features = ['userRatingCount', 'isCorporateEmailScore', 'adSpent', 'appAge', 'averageUserRating']\n",
    "\n",
    "# Kolom 'Downloads' perlu diproses secara khusus karena berbentuk rentang string\n",
    "downloads_feature = [\"downloads\"]\n",
    "\n",
    "# Fitur kategori (nominal) yang akan dienkode menggunakan OneHotEncoder\n",
    "categorical_features = ['developerCountry', 'countryCode', 'primaryGenreName', 'deviceType',\n",
    "                        'hasPrivacyLink', 'hasTermsOfServiceLink']\n",
    "\n",
    "# Fitur ordinal dengan nilai terurut (\"low\", \"medium\", \"high\")\n",
    "ordinal_features = ['hasTermsOfServiceLinkRating', 'appContentBrandSafetyRating', \n",
    "                    'appDescriptionBrandSafetyRating', 'mfaRating']\n",
    "\n",
    "# --- MEMBANGUN PIPELINE UNTUK PREPROCESSING ---\n",
    "\n",
    "# Pipeline untuk fitur numerik\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline khusus untuk fitur \"Downloads\"\n",
    "downloads_pipeline = Pipeline(steps=[\n",
    "    (\"download_parser\", download_transformer),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "# Pipeline untuk fitur kategori dengan konversi ke string\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"to_str\", FunctionTransformer(lambda X: X.astype(str))),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Pipeline untuk fitur ordinal; asumsikan urutan kategorinya adalah [\"low\", \"medium\", \"high\"]\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"low\")),\n",
    "    (\"ordinal\", OrdinalEncoder(categories=[[\"low\", \"medium\", \"high\"]]*len(ordinal_features)))\n",
    "])\n",
    "\n",
    "# Gabungkan semua pipeline di dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"downloads\", downloads_pipeline, downloads_feature),\n",
    "    (\"cat\", categorical_transformer, categorical_features),\n",
    "    (\"ord\", ordinal_transformer, ordinal_features)\n",
    "])\n",
    "\n",
    "# --- MEMBANGUN PIPELINE MODEL ---\n",
    "# Kami gunakan RandomForestClassifier sebagai contoh\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# --- EVALUASI MODEL (Optional) ---\n",
    "# Misalkan kita ingin melakukan cross-validation pada data latih:\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"CV Accuracy scores: \", cv_scores)\n",
    "print(\"Rata-rata CV Accuracy: \", np.mean(cv_scores))\n",
    "\n",
    "# --- MELATIH MODEL PADA DATA LATIH ---\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# --- MEMPREDIKSI DATA UJI ---\n",
    "# Pastikan bahwa struktur data pada test_df sama dengan X_train (misalnya, urutan dan nama kolom fitur)\n",
    "test_predictions = clf.predict(test_df)\n",
    "\n",
    "# Jika ingin mendapatkan probabilitas (misalnya untuk thresholding), bisa gunakan clf.predict_proba(test_df)\n",
    "\n",
    "# --- MEMBENTUK FILE SUBMISSION ---\n",
    "# Format file submission biasanya mengikuti struktur submission_format.csv\n",
    "# Misal submission_format memiliki kolom 'id' dan 'coppaRisk'\n",
    "# Jika test_df atau submission_format memiliki kolom 'id', gunakan sebagai identifier\n",
    "if \"id\" in submission_format.columns:\n",
    "    submission = pd.DataFrame({\n",
    "        \"id\": submission_format[\"id\"],\n",
    "        \"coppaRisk\": test_predictions  # Atau bisa dipetakan ke label yang sesuai\n",
    "    })\n",
    "else:\n",
    "    # Jika tidak ada kolom 'id', asumsikan barisnya sesuai urutan\n",
    "    submission = pd.DataFrame({\n",
    "        \"coppaRisk\": test_predictions\n",
    "    })\n",
    "\n",
    "# Simpan hasil prediksi ke file CSV\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"File submission.csv telah disimpan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "769fa9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = pd.concat([submission_format,submission],axis=1)\n",
    "merge_data.to_csv(\"submission_format2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a0f00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format.drop('coppaRisk', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61ced906",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format.to_csv(\"submission_format2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3039e48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (sebelum tuning): [0.90214286 0.90571429 0.9        0.89785714 0.89928571]\n",
      "Rata-rata CV Accuracy: 0.901\n",
      "\n",
      "Best Parameters: {'classifier__learning_rate': 0.01, 'classifier__max_depth': 5, 'classifier__n_estimators': 150}\n",
      "Best CV Accuracy: 0.9027142857142858\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Fungsi untuk mengonversi kolom Downloads dari format \"min - max\" menjadi rata-rata\n",
    "def parse_download_range(X):\n",
    "    # Jika X berupa DataFrame, ambil kolom pertama\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.iloc[:, 0].values\n",
    "    def convert_range(s):\n",
    "        try:\n",
    "            parts = str(s).split('-')\n",
    "            if len(parts) != 2:\n",
    "                return np.nan\n",
    "            low = float(parts[0].strip().replace(',', ''))\n",
    "            high = float(parts[1].strip().replace(',', ''))\n",
    "            return (low + high) / 2\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    result = np.array([convert_range(val) for val in X])\n",
    "    return result.reshape(-1, 1)\n",
    "\n",
    "# Transformer untuk kolom Downloads\n",
    "download_transformer = FunctionTransformer(parse_download_range, validate=False)\n",
    "\n",
    "# --- MENDEFINISIKAN FITUR ---\n",
    "# Fitur numerik\n",
    "numeric_features = ['userRatingCount', 'isCorporateEmailScore', 'adSpent', 'appAge', 'averageUserRating']\n",
    "\n",
    "# Kolom Downloads (jika tersedia)\n",
    "downloads_feature = [\"downloads\"]\n",
    "\n",
    "# Fitur kategori (pastikan nilai-nilainya homogen dengan konversi ke string)\n",
    "categorical_features = ['developerCountry', 'countryCode', 'primaryGenreName', 'deviceType',\n",
    "                        'hasPrivacyLink', 'hasTermsOfServiceLink']\n",
    "\n",
    "# Fitur ordinal (dengan asumsi urutan: low < medium < high)\n",
    "ordinal_features = ['hasTermsOfServiceLinkRating', 'appContentBrandSafetyRating', \n",
    "                    'appDescriptionBrandSafetyRating', 'mfaRating']\n",
    "\n",
    "# Pipeline untuk fitur numerik\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline untuk fitur Downloads\n",
    "downloads_pipeline = Pipeline(steps=[\n",
    "    (\"download_parser\", download_transformer),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline untuk fitur kategori (dengan konversi ke string agar tipe data homogen)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"to_str\", FunctionTransformer(lambda X: X.astype(str))),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Pipeline untuk fitur ordinal\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"low\")),\n",
    "    (\"ordinal\", OrdinalEncoder(categories=[[\"low\", \"medium\", \"high\"]] * len(ordinal_features)))\n",
    "])\n",
    "\n",
    "# Gabungkan semua transformer ke dalam ColumnTransformer.\n",
    "# Jika kolom Downloads tidak ada di data, Anda bisa mengomentari bagian berikut.\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"downloads\", downloads_pipeline, downloads_feature),\n",
    "    (\"cat\", categorical_transformer, categorical_features),\n",
    "    (\"ord\", ordinal_transformer, ordinal_features)\n",
    "])\n",
    "\n",
    "# --- MEMBACA DATA ---\n",
    "# Asumsikan data sudah ada di file train.csv (atau hasil merge dengan target.csv jika diperlukan)\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "# Jika target terpisah di file lain, lakukan merge dulu:\n",
    "# target_df = pd.read_csv(\"target.csv\")\n",
    "# train_df = pd.merge(train_df, target_df, on=\"id\")\n",
    "\n",
    "# Misalnya, target variabel adalah 'coppaRisk'\n",
    "target_column = \"coppaRisk\"\n",
    "\n",
    "X_train = train_df.drop(columns=[target_column])\n",
    "y_train = train_df[target_column]\n",
    "\n",
    "# --- MODEL ALTERNATIF: GradientBoostingClassifier ---\n",
    "# Membuat pipeline dengan model GradientBoostingClassifier\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Evaluasi awal dengan cross validation\n",
    "cv_scores = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"CV Accuracy (sebelum tuning):\", cv_scores)\n",
    "print(\"Rata-rata CV Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "\n",
    "# --- HYPERPARAMETER TUNING DENGAN GridSearchCV ---\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [50, 100, 150],\n",
    "    \"classifier__learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"classifier__max_depth\": [3, 5, 7],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Setelah tuning, Anda bisa menggunakan grid_search.best_estimator_ sebagai model akhir\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Jika ingin memprediksi data test:\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "predictions = best_model.predict(test_df)\n",
    "# contoh pembuatan file submission:\n",
    "submission = pd.DataFrame({\n",
    "    # sesuaikan dengan kolom identifikasi\n",
    "    \"coppaRisk\": predictions\n",
    "})\n",
    "submission.to_csv(\"submission2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0957605e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_imputed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_imputed\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_imputed' is not defined"
     ]
    }
   ],
   "source": [
    "df_imputed.to_csv(\"imputed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
